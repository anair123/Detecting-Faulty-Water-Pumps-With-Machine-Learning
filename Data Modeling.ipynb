{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a381e72e",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aashi\\Desktop\\Personal Projects\\Data Science\\Identifying-Faulty-Water-Pumps-With-Machine-Learning\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from feature_engine.imputation import CategoricalImputer, DropMissingData\n",
    "from feature_engine.encoding import RareLabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e08dfe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = pd.read_csv('data/train_values.csv')\n",
    "train_label = pd.read_csv('data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe14c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two data frames\n",
    "df = train_values.merge(train_label, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72726eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that all rows were in the joined dataset\n",
    "len(df) == len(train_label) == len(train_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1380246f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'amount_tsh', 'date_recorded', 'funder', 'gps_height',\n",
       "       'installer', 'longitude', 'latitude', 'wpt_name', 'num_private',\n",
       "       'basin', 'subvillage', 'region', 'region_code', 'district_code', 'lga',\n",
       "       'ward', 'population', 'public_meeting', 'recorded_by',\n",
       "       'scheme_management', 'scheme_name', 'permit', 'construction_year',\n",
       "       'extraction_type', 'extraction_type_group', 'extraction_type_class',\n",
       "       'management', 'management_group', 'payment', 'payment_type',\n",
       "       'water_quality', 'quality_group', 'quantity', 'quantity_group',\n",
       "       'source', 'source_type', 'source_class', 'waterpoint_type',\n",
       "       'waterpoint_type_group', 'status_group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "283cf637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>...</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, amount_tsh, date_recorded, funder, gps_height, installer, longitude, latitude, wpt_name, num_private, basin, subvillage, region, region_code, district_code, lga, ward, population, public_meeting, recorded_by, scheme_management, scheme_name, permit, construction_year, extraction_type, extraction_type_group, extraction_type_class, management, management_group, payment, payment_type, water_quality, quality_group, quantity, quantity_group, source, source_type, source_class, waterpoint_type, waterpoint_type_group, status_group]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 41 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for duplicates \n",
    "df[df['id'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72abafcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>number of missing values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>funder</td>\n",
       "      <td>3637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>installer</td>\n",
       "      <td>3655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wpt_name</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>subvillage</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>public_meeting</td>\n",
       "      <td>3334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>scheme_management</td>\n",
       "      <td>3878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>scheme_name</td>\n",
       "      <td>28810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>permit</td>\n",
       "      <td>3056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               column  number of missing values\n",
       "3              funder                      3637\n",
       "5           installer                      3655\n",
       "8            wpt_name                         2\n",
       "11         subvillage                       371\n",
       "18     public_meeting                      3334\n",
       "20  scheme_management                      3878\n",
       "21        scheme_name                     28810\n",
       "22             permit                      3056"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = pd.DataFrame(df.isnull().sum()).reset_index()\n",
    "missing.columns = ['column', 'number of missing values']\n",
    "missing[missing['number of missing values']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca697fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4690675",
   "metadata": {},
   "source": [
    "### Remove Unwanted Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccb402b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6835f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uneeded columns (fields that don't help predict the target label)\n",
    "unneeded_col = ['id', 'recorded_by', 'wpt_name']\n",
    "df = df.drop(unneeded_col, axis=1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b41cfcb2",
   "metadata": {},
   "source": [
    "### Handling Fields with Too Many Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caf562c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field</th>\n",
       "      <th>Number of Unique Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date_recorded</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>funder</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>installer</td>\n",
       "      <td>2145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basin</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subvillage</td>\n",
       "      <td>19287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Field  Number of Unique Values\n",
       "0  date_recorded                      356\n",
       "1         funder                     1896\n",
       "2      installer                     2145\n",
       "3          basin                        9\n",
       "4     subvillage                    19287"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all categorical variables\n",
    "df['region_code'] = df['region_code'].astype('object')\n",
    "df['district_code'] = df['district_code'].astype('object')\n",
    "\n",
    "cat_var = [col for col in df.columns if df[col].dtypes == 'object']\n",
    "col_count = {}\n",
    "\n",
    "# find number of unique values in each categorical variable\n",
    "for col in cat_var:\n",
    "    count = df[col].nunique()\n",
    "    col_count[col] = count\n",
    "col_count_df = pd.DataFrame(col_count.items())\n",
    "col_count_df.columns = ['Field', 'Number of Unique Values']\n",
    "col_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3018ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redundant data (fields with information provided in other columns)\n",
    "redundant_col = ['subvillage','latitude', 'longitude', 'region_code', 'district_code', 'lga', 'ward', 'scheme_name', 'extraction_type', 'extraction_type_group', 'payment', 'water_quality', 'quantity', 'source', 'source_type', 'waterpoint_type', 'management']\n",
    "\n",
    "df = df.drop(redundant_col, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ca6943c",
   "metadata": {},
   "source": [
    "### Handle Fields with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fb2ef1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date_recorded': 356,\n",
       " 'funder': 1896,\n",
       " 'installer': 2145,\n",
       " 'basin': 9,\n",
       " 'region': 21,\n",
       " 'public_meeting': 2,\n",
       " 'scheme_management': 11,\n",
       " 'permit': 2,\n",
       " 'extraction_type_class': 7,\n",
       " 'management_group': 5,\n",
       " 'payment_type': 7,\n",
       " 'quality_group': 6,\n",
       " 'quantity_group': 5,\n",
       " 'source_class': 3,\n",
       " 'waterpoint_type_group': 6,\n",
       " 'status_group': 3}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_var = [col for col in df.columns if df[col].dtypes == 'object']\n",
    "col_count = {}\n",
    "\n",
    "# find number of unique values in each categorical variable\n",
    "for col in cat_var:\n",
    "    count = df[col].nunique()\n",
    "    col_count[col] = count\n",
    "col_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "131e330e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>% missing values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>funder</td>\n",
       "      <td>6.122896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>installer</td>\n",
       "      <td>6.153199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>public_meeting</td>\n",
       "      <td>5.612795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>scheme_management</td>\n",
       "      <td>6.528620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>permit</td>\n",
       "      <td>5.144781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               column  % missing values\n",
       "2              funder          6.122896\n",
       "4           installer          6.153199\n",
       "9      public_meeting          5.612795\n",
       "10  scheme_management          6.528620\n",
       "11             permit          5.144781"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = pd.DataFrame(df.isnull().sum()/len(df)*100).reset_index()\n",
    "missing.columns = ['column', '% missing values']\n",
    "missing[missing['% missing values']>0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8bbfd0b",
   "metadata": {},
   "source": [
    "### Handle Date Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a777fec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive age of water pump (i.e., years since construction)\n",
    "df['construction_year'] = pd.to_datetime(df['construction_year'])\n",
    "df['date_recorded'] = pd.to_datetime(df['date_recorded'])\n",
    "df['age'] = (df['date_recorded'] - df['construction_year']) / np.timedelta64(1, 'Y')\n",
    "\n",
    "# delete construction_year and date_recorded columns \n",
    "df = df.drop(['construction_year', 'date_recorded'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6852ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amount_tsh', 'gps_height', 'num_private', 'population', 'age']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get quantifiable variables\n",
    "num_var = [col for col in df.columns if df[col].dtypes in ['float64', 'int64']]\n",
    "num_var"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e00674e6",
   "metadata": {},
   "source": [
    "### Testing Numerical Features With ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5a46aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount_tsh                  0\n",
       "funder                   3637\n",
       "gps_height                  0\n",
       "installer                3655\n",
       "num_private                 0\n",
       "basin                       0\n",
       "region                      0\n",
       "population                  0\n",
       "public_meeting           3334\n",
       "scheme_management        3878\n",
       "permit                   3056\n",
       "extraction_type_class       0\n",
       "management_group            0\n",
       "payment_type                0\n",
       "quality_group               0\n",
       "quantity_group              0\n",
       "source_class                0\n",
       "waterpoint_type_group       0\n",
       "status_group                0\n",
       "age                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74d35631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# copy the dataset for ANOVA test\n",
    "df_int = df.copy(deep=True)\n",
    "\n",
    "# keep the numerical columns and the target label\n",
    "int_var = [col for col in df.columns if df[col].dtypes in ['int64', 'float64']] + ['status_group']\n",
    "df_int = df_int[int_var]\n",
    "\n",
    "# get the input and output variables\n",
    "X = df_int.drop('status_group', axis=1)\n",
    "y = df_int['status_group']\n",
    "\n",
    "# compute the ANOVA F-statistic for each column\n",
    "select = SelectKBest(f_classif, k=5)\n",
    "fit = select.fit(X, y)\n",
    "\n",
    "# compute the p-values for each F-statistic\n",
    "p_values = {col: np.round(p_value, 4) for col, p_value in zip(X.columns, fit.pvalues_)}\n",
    "\n",
    "p_values = pd.Series(p_values.values(),index = p_values.keys())\n",
    "p_values.sort_values(ascending = False , inplace = True)\n",
    "p_values.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41ad2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns with high p-values from ANOVA test\n",
    "anova_drop = ['num_private']\n",
    "df = df.drop(anova_drop, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb71356c",
   "metadata": {},
   "source": [
    "### Testing Categorical Features With Chi-Square Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8a318e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the dataframe for chi square tests\n",
    "df_chi = df.copy(deep=True)\n",
    "\n",
    "# keep the categorical variables in the data frame\n",
    "cat_var = [col for col in df_chi.columns if df[col].dtypes == 'object']\n",
    "df_chi = df_chi[cat_var]\n",
    "\n",
    "# encode the categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "for col in df_chi.columns:\n",
    "    df_chi[col] = label_encoder.fit_transform(df_chi[col])\n",
    "\n",
    "# get input and output variables\n",
    "X = df_chi.drop('status_group',axis=1)\n",
    "y = df_chi['status_group']\n",
    "\n",
    "# perform chi-square tests\n",
    "chi_scores = chi2(X,y)\n",
    "p_values = pd.Series(chi_scores[1],index = X.columns)\n",
    "p_values.sort_values(ascending = False , inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90fc4100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,2))\n",
    "p_values.plot.bar()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "895d1ed7",
   "metadata": {},
   "source": [
    "### Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f169c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('status_group', axis=1)\n",
    "y = df['status_group']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76d31d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount_tsh                  0\n",
       "funder                   2548\n",
       "gps_height                  0\n",
       "installer                2555\n",
       "basin                       0\n",
       "region                      0\n",
       "population                  0\n",
       "public_meeting           2297\n",
       "scheme_management        2733\n",
       "permit                   2151\n",
       "extraction_type_class       0\n",
       "management_group            0\n",
       "payment_type                0\n",
       "quality_group               0\n",
       "quantity_group              0\n",
       "source_class                0\n",
       "waterpoint_type_group       0\n",
       "age                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b940a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the target label\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "995200eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a dummy classifier\n",
    "dummy_clf = DummyClassifier(strategy=\"uniform\", random_state=42)\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dummy = dummy_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82d80a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column transformer\n",
    "cat_var = [ind for ind, col in enumerate(X_train.columns) if X_train[col].dtypes=='object']\n",
    "num_var = [ind for ind, col in enumerate(X_train.columns) if X_train[col].dtypes in ['int64', 'float64']]\n",
    "\n",
    "# Define column transformer for one-hot encoding categorical features\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    ('cat_transformer', categorical_transformer, cat_var)\n",
    "  # replace missing categorical values with mode and one-hot encode\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Define final pipeline with preprocessing and logistic regression model\n",
    "pipeline_log = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('logistic_regression', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline_log.fit(X_train, y_train)\n",
    "y_pred_log = pipeline_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "896d07fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2 score of dummy classifier: 0.32895622895622895\n",
      "F2 score of logistic regression classifier: 0.6836139169472503\n"
     ]
    }
   ],
   "source": [
    "f2_score_dummy = fbeta_score(y_test, y_pred_dummy, average='micro', beta=2)\n",
    "f2_score_log = fbeta_score(y_test, y_pred_log, average='micro', beta=2)\n",
    "\n",
    "print(f'F2 score of dummy classifier: {f2_score_dummy}')\n",
    "print(f'F2 score of logistic regression classifier: {f2_score_log}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42193880",
   "metadata": {},
   "source": [
    "### CatBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c607cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a f2 score metric for hyperparameter tuning\n",
    "def f2_score(y_true, y_pred):\n",
    "    return fbeta_score(y_true, y_pred, beta=2, average='weighted')\n",
    "f2_scorer = make_scorer(f2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c5092cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-07 08:41:01,905]\u001b[0m A new study created in memory with name: no-name-c6b895a8-b91b-4af1-86b7-479fa805bd7f\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 08:47:59,615]\u001b[0m Trial 0 finished with value: 0.7724146224146224 and parameters: {'learning_rate': 0.07566381245104299, 'iterations': 900, 'depth': 8}. Best is trial 0 with value: 0.7724146224146224.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 08:50:11,203]\u001b[0m Trial 1 finished with value: 0.762025012025012 and parameters: {'learning_rate': 0.08461850692932245, 'iterations': 300, 'depth': 8}. Best is trial 0 with value: 0.7724146224146224.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 08:50:26,601]\u001b[0m Trial 2 finished with value: 0.734968734968735 and parameters: {'learning_rate': 0.06344004792050323, 'iterations': 100, 'depth': 6}. Best is trial 0 with value: 0.7724146224146224.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 08:51:45,195]\u001b[0m Trial 3 finished with value: 0.7496151996151995 and parameters: {'learning_rate': 0.06064554164685285, 'iterations': 300, 'depth': 6}. Best is trial 0 with value: 0.7724146224146224.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 08:52:11,448]\u001b[0m Trial 4 finished with value: 0.7525493025493025 and parameters: {'learning_rate': 0.09862621758474008, 'iterations': 100, 'depth': 9}. Best is trial 0 with value: 0.7724146224146224.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 08:55:55,192]\u001b[0m Trial 5 finished with value: 0.7536796536796536 and parameters: {'learning_rate': 0.028822321020613096, 'iterations': 900, 'depth': 6}. Best is trial 0 with value: 0.7724146224146224.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 08:56:10,840]\u001b[0m Trial 6 finished with value: 0.7405242905242906 and parameters: {'learning_rate': 0.09800723126843662, 'iterations': 100, 'depth': 6}. Best is trial 0 with value: 0.7724146224146224.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 08:57:47,978]\u001b[0m Trial 7 finished with value: 0.7542568542568543 and parameters: {'learning_rate': 0.06420871237666846, 'iterations': 300, 'depth': 7}. Best is trial 0 with value: 0.7724146224146224.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 08:58:24,707]\u001b[0m Trial 8 finished with value: 0.7443001443001442 and parameters: {'learning_rate': 0.0421202670112848, 'iterations': 100, 'depth': 10}. Best is trial 0 with value: 0.7724146224146224.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 08:59:59,489]\u001b[0m Trial 9 finished with value: 0.7532708032708033 and parameters: {'learning_rate': 0.08873993807662102, 'iterations': 500, 'depth': 5}. Best is trial 0 with value: 0.7724146224146224.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 09:07:17,366]\u001b[0m Trial 10 finished with value: 0.7358826358826359 and parameters: {'learning_rate': 0.003972612107627428, 'iterations': 1000, 'depth': 8}. Best is trial 0 with value: 0.7724146224146224.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 09:12:36,387]\u001b[0m Trial 11 finished with value: 0.7713804713804714 and parameters: {'learning_rate': 0.08055033134252076, 'iterations': 700, 'depth': 8}. Best is trial 0 with value: 0.7724146224146224.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 09:19:29,861]\u001b[0m Trial 12 finished with value: 0.7718133718133718 and parameters: {'learning_rate': 0.07703080718541488, 'iterations': 800, 'depth': 8}. Best is trial 0 with value: 0.7724146224146224.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 09:32:22,834]\u001b[0m Trial 13 finished with value: 0.7737854737854738 and parameters: {'learning_rate': 0.07522623014101364, 'iterations': 800, 'depth': 10}. Best is trial 13 with value: 0.7737854737854738.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 09:43:34,996]\u001b[0m Trial 14 finished with value: 0.7731601731601732 and parameters: {'learning_rate': 0.07384816345250644, 'iterations': 700, 'depth': 10}. Best is trial 13 with value: 0.7737854737854738.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 09:53:30,668]\u001b[0m Trial 15 finished with value: 0.7717652717652718 and parameters: {'learning_rate': 0.05163998432818262, 'iterations': 600, 'depth': 10}. Best is trial 13 with value: 0.7737854737854738.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 10:02:14,506]\u001b[0m Trial 16 finished with value: 0.7733525733525735 and parameters: {'learning_rate': 0.07165564875397983, 'iterations': 600, 'depth': 10}. Best is trial 13 with value: 0.7737854737854738.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 10:07:26,774]\u001b[0m Trial 17 finished with value: 0.7702501202501203 and parameters: {'learning_rate': 0.06810083972040537, 'iterations': 500, 'depth': 9}. Best is trial 13 with value: 0.7737854737854738.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 10:08:59,311]\u001b[0m Trial 18 finished with value: 0.7502164502164502 and parameters: {'learning_rate': 0.08814298957955208, 'iterations': 600, 'depth': 4}. Best is trial 13 with value: 0.7737854737854738.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 10:17:07,616]\u001b[0m Trial 19 finished with value: 0.7721981721981722 and parameters: {'learning_rate': 0.05267089330259928, 'iterations': 800, 'depth': 9}. Best is trial 13 with value: 0.7737854737854738.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 10:22:48,263]\u001b[0m Trial 20 finished with value: 0.7696248196248195 and parameters: {'learning_rate': 0.07082411601667374, 'iterations': 400, 'depth': 10}. Best is trial 13 with value: 0.7737854737854738.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 10:33:17,165]\u001b[0m Trial 21 finished with value: 0.7737133237133237 and parameters: {'learning_rate': 0.07270716495421285, 'iterations': 700, 'depth': 10}. Best is trial 13 with value: 0.7737854737854738.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 10:40:55,117]\u001b[0m Trial 22 finished with value: 0.7733525733525733 and parameters: {'learning_rate': 0.08421238834655032, 'iterations': 700, 'depth': 9}. Best is trial 13 with value: 0.7737854737854738.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 10:53:13,168]\u001b[0m Trial 23 finished with value: 0.7738816738816738 and parameters: {'learning_rate': 0.07009226068006832, 'iterations': 800, 'depth': 10}. Best is trial 23 with value: 0.7738816738816738.\u001b[0m\n",
      "\u001b[33m[W 2023-05-07 10:58:25,600]\u001b[0m Trial 24 failed with parameters: {'learning_rate': 0.05908177249589367, 'iterations': 800, 'depth': 9} because of the following error: CatBoostError('bad allocation').\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\aashi\\Desktop\\Personal Projects\\Data Science\\Identifying-Faulty-Water-Pumps-With-Machine-Learning\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\aashi\\AppData\\Local\\Temp\\ipykernel_3872\\3678141337.py\", line 40, in objective\n",
      "    pipeline_cbc.fit(X_train_split, y_train_split)\n",
      "  File \"c:\\Users\\aashi\\Desktop\\Personal Projects\\Data Science\\Identifying-Faulty-Water-Pumps-With-Machine-Learning\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\aashi\\Desktop\\Personal Projects\\Data Science\\Identifying-Faulty-Water-Pumps-With-Machine-Learning\\venv\\lib\\site-packages\\catboost\\core.py\", line 5128, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"c:\\Users\\aashi\\Desktop\\Personal Projects\\Data Science\\Identifying-Faulty-Water-Pumps-With-Machine-Learning\\venv\\lib\\site-packages\\catboost\\core.py\", line 2355, in _fit\n",
      "    self._train(\n",
      "  File \"c:\\Users\\aashi\\Desktop\\Personal Projects\\Data Science\\Identifying-Faulty-Water-Pumps-With-Machine-Learning\\venv\\lib\\site-packages\\catboost\\core.py\", line 1759, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4623, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4672, in _catboost._CatBoost._train\n",
      "_catboost.CatBoostError: bad allocation\n",
      "\u001b[33m[W 2023-05-07 10:58:25,727]\u001b[0m Trial 24 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "bad allocation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(f2_scores)\n\u001b[0;32m     47\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\aashi\\Desktop\\Personal Projects\\Data Science\\Identifying-Faulty-Water-Pumps-With-Machine-Learning\\venv\\lib\\site-packages\\optuna\\study\\study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    332\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \n\u001b[0;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m     _optimize(\n\u001b[0;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    435\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aashi\\Desktop\\Personal Projects\\Data Science\\Identifying-Faulty-Water-Pumps-With-Machine-Learning\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\aashi\\Desktop\\Personal Projects\\Data Science\\Identifying-Faulty-Water-Pumps-With-Machine-Learning\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\aashi\\Desktop\\Personal Projects\\Data Science\\Identifying-Faulty-Water-Pumps-With-Machine-Learning\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\aashi\\Desktop\\Personal Projects\\Data Science\\Identifying-Faulty-Water-Pumps-With-Machine-Learning\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[27], line 40\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     37\u001b[0m X_train_split, X_test_split \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39miloc[train_idx], X_train\u001b[39m.\u001b[39miloc[test_idx]\n\u001b[0;32m     38\u001b[0m y_train_split, y_test_split \u001b[39m=\u001b[39m y_train_df\u001b[39m.\u001b[39miloc[train_idx], y_train_df\u001b[39m.\u001b[39miloc[test_idx]\n\u001b[1;32m---> 40\u001b[0m pipeline_cbc\u001b[39m.\u001b[39;49mfit(X_train_split, y_train_split)\n\u001b[0;32m     41\u001b[0m y_pred \u001b[39m=\u001b[39m pipeline_cbc\u001b[39m.\u001b[39mpredict(X_test_split)\n\u001b[0;32m     43\u001b[0m f2_scores\u001b[39m.\u001b[39mappend(fbeta_score(y_test_split, y_pred, beta\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmicro\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\aashi\\Desktop\\Personal Projects\\Data Science\\Identifying-Faulty-Water-Pumps-With-Machine-Learning\\venv\\lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    407\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aashi\\Desktop\\Personal Projects\\Data Science\\Identifying-Faulty-Water-Pumps-With-Machine-Learning\\venv\\lib\\site-packages\\catboost\\core.py:5128\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m   5126\u001b[0m     CatBoostClassifier\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m-> 5128\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline, use_best_model,\n\u001b[0;32m   5129\u001b[0m           eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period,\n\u001b[0;32m   5130\u001b[0m           silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[0;32m   5131\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aashi\\Desktop\\Personal Projects\\Data Science\\Identifying-Faulty-Water-Pumps-With-Machine-Learning\\venv\\lib\\site-packages\\catboost\\core.py:2355\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2351\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2353\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[0;32m   2354\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2355\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[0;32m   2356\u001b[0m         train_pool,\n\u001b[0;32m   2357\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2358\u001b[0m         params,\n\u001b[0;32m   2359\u001b[0m         allow_clear_pool,\n\u001b[0;32m   2360\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m   2361\u001b[0m     )\n\u001b[0;32m   2363\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2364\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32mc:\\Users\\aashi\\Desktop\\Personal Projects\\Data Science\\Identifying-Faulty-Water-Pumps-With-Machine-Learning\\venv\\lib\\site-packages\\catboost\\core.py:1759\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1758\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1759\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   1760\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:4623\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4672\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCatBoostError\u001b[0m: bad allocation"
     ]
    }
   ],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.001, 0.1),\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000, step=100),\n",
    "        'depth': trial.suggest_int('depth', 4, 10)\n",
    "    }\n",
    "\n",
    "    cat_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "    cat_indices = [i for i, col in enumerate(X_train.columns) if X_train[col].dtypes =='object']\n",
    "    num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    # Get list of columns with missing values\n",
    "    cols_with_missing = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "\n",
    "    # set up the wrapper with the SimpleImputer\n",
    "    imputer = SklearnTransformerWrapper(transformer = SimpleImputer(strategy='most_frequent'),\n",
    "                                        variables = cols_with_missing)\n",
    "\n",
    "    scaler = SklearnTransformerWrapper(transformer=StandardScaler(),\n",
    "                                    variables=num_cols)\n",
    "\n",
    "\n",
    "    pipeline_cbc = Pipeline(steps=[('impute', imputer),\n",
    "                            ('scaler', scaler),\n",
    "                            ('rare_label', RareLabelEncoder(replace_with='Other', n_categories=10, variables=cat_cols)),\n",
    "                            ('catboost', CatBoostClassifier(**params, verbose=False, cat_features=cat_indices, early_stopping_rounds=50))\n",
    "                                ])\n",
    "    \n",
    "    # Define cross-validation method\n",
    "    sfk = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    y_train_df = pd.Series(y_train)\n",
    "\n",
    "     # Train and evaluate model using f1_score\n",
    "    f2_scores = []\n",
    "    for train_idx, test_idx in sfk.split(X_train, y_train_df):\n",
    "        X_train_split, X_test_split = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "        y_train_split, y_test_split = y_train_df.iloc[train_idx], y_train_df.iloc[test_idx]\n",
    "\n",
    "        pipeline_cbc.fit(X_train_split, y_train_split)\n",
    "        y_pred = pipeline_cbc.predict(X_test_split)\n",
    "\n",
    "        f2_scores.append(fbeta_score(y_test_split, y_pred, beta=2, average='micro'))\n",
    "\n",
    "    return np.mean(f2_scores)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb123385",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "# perform one hot encoding on the categorical features\n",
    "\n",
    "cat_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "cat_indices = [i for i, col in enumerate(X_train.columns) if X_train[col].dtypes =='object']\n",
    "num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Get list of columns with missing values\n",
    "cols_with_missing = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "# sspecify columns for imputer\n",
    "imputer = SklearnTransformerWrapper(transformer = SimpleImputer(strategy='most_frequent'),\n",
    "                                    variables = cols_with_missing)\n",
    "\n",
    "# specify columns for standard scaler\n",
    "scaler = SklearnTransformerWrapper(transformer=StandardScaler(),\n",
    "                                variables=num_cols)\n",
    "\n",
    "# create pipeline\n",
    "pipeline_cbc = Pipeline(steps=[('impute', SklearnTransformerWrapper(transformer = SimpleImputer(strategy='most_frequent'),\n",
    "                                    variables = cols_with_missing)),\n",
    "                            ('scaler', SklearnTransformerWrapper(transformer=StandardScaler(),\n",
    "                                variables=num_cols)),\n",
    "                            ('rare_label', RareLabelEncoder(replace_with='Unknown', n_categories=10, variables=cat_cols)),\n",
    "                            ('catboost', CatBoostClassifier(**best_params, verbose=False, cat_features=cat_indices, early_stopping_rounds=50))\n",
    "                                ])\n",
    "\n",
    "# fit pipeline\n",
    "pipeline_cbc.fit(X_train, y_train)\n",
    "\n",
    "#generate predictions\n",
    "y_pred_cbc= pipeline_cbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c781933",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2_score_cbc = fbeta_score(y_pred_cbc, y_test, beta=2, average='micro')\n",
    "f2_score_cbc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39591a86",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ae4b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-06 18:20:13,996]\u001b[0m A new study created in memory with name: no-name-9972e29d-07be-4dcf-924f-eedeafe3304e\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:20:23,209]\u001b[0m Trial 0 finished with value: 0.7600769600769602 and parameters: {'learning_rate': 0.013163963093274663, 'num_leaves': 167, 'max_depth': 10}. Best is trial 0 with value: 0.7600769600769602.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:20:25,233]\u001b[0m Trial 1 finished with value: 0.7562289562289563 and parameters: {'learning_rate': 0.06566877903447202, 'num_leaves': 46, 'max_depth': 4}. Best is trial 0 with value: 0.7600769600769602.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:20:28,318]\u001b[0m Trial 2 finished with value: 0.7635882635882636 and parameters: {'learning_rate': 0.04892530298039127, 'num_leaves': 27, 'max_depth': 7}. Best is trial 2 with value: 0.7635882635882636.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:20:41,595]\u001b[0m Trial 3 finished with value: 0.7771765271765272 and parameters: {'learning_rate': 0.024573975198419022, 'num_leaves': 166, 'max_depth': 12}. Best is trial 3 with value: 0.7771765271765272.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:20:53,759]\u001b[0m Trial 4 finished with value: 0.7777777777777778 and parameters: {'learning_rate': 0.0384946412216908, 'num_leaves': 181, 'max_depth': 11}. Best is trial 4 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:21:00,078]\u001b[0m Trial 5 finished with value: 0.7708994708994709 and parameters: {'learning_rate': 0.047229717295058864, 'num_leaves': 216, 'max_depth': 8}. Best is trial 4 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:21:06,540]\u001b[0m Trial 6 finished with value: 0.7680134680134681 and parameters: {'learning_rate': 0.061926672836435395, 'num_leaves': 160, 'max_depth': 7}. Best is trial 4 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:21:11,093]\u001b[0m Trial 7 finished with value: 0.7673881673881674 and parameters: {'learning_rate': 0.03819177174958012, 'num_leaves': 209, 'max_depth': 7}. Best is trial 4 with value: 0.7777777777777778.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:21:17,193]\u001b[0m Trial 8 finished with value: 0.7782347282347283 and parameters: {'learning_rate': 0.04351427395994283, 'num_leaves': 106, 'max_depth': 12}. Best is trial 8 with value: 0.7782347282347283.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:21:23,422]\u001b[0m Trial 9 finished with value: 0.7704425204425204 and parameters: {'learning_rate': 0.01916639853517728, 'num_leaves': 91, 'max_depth': 12}. Best is trial 8 with value: 0.7782347282347283.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:21:29,608]\u001b[0m Trial 10 finished with value: 0.7752044252044251 and parameters: {'learning_rate': 0.09388846567622106, 'num_leaves': 101, 'max_depth': 10}. Best is trial 8 with value: 0.7782347282347283.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:21:40,798]\u001b[0m Trial 11 finished with value: 0.7772005772005772 and parameters: {'learning_rate': 0.03218687219564075, 'num_leaves': 251, 'max_depth': 10}. Best is trial 8 with value: 0.7782347282347283.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:21:50,046]\u001b[0m Trial 12 finished with value: 0.7354978354978355 and parameters: {'learning_rate': 0.0029650371623194463, 'num_leaves': 113, 'max_depth': 12}. Best is trial 8 with value: 0.7782347282347283.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:21:56,128]\u001b[0m Trial 13 finished with value: 0.7742183742183743 and parameters: {'learning_rate': 0.03650407067988487, 'num_leaves': 63, 'max_depth': 11}. Best is trial 8 with value: 0.7782347282347283.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:22:05,320]\u001b[0m Trial 14 finished with value: 0.7736171236171235 and parameters: {'learning_rate': 0.0600364196387041, 'num_leaves': 140, 'max_depth': 9}. Best is trial 8 with value: 0.7782347282347283.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:22:06,759]\u001b[0m Trial 15 finished with value: 0.7122174122174122 and parameters: {'learning_rate': 0.03222694146455175, 'num_leaves': 2, 'max_depth': 4}. Best is trial 8 with value: 0.7782347282347283.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:22:19,081]\u001b[0m Trial 16 finished with value: 0.7776094276094275 and parameters: {'learning_rate': 0.04526604559845021, 'num_leaves': 198, 'max_depth': 11}. Best is trial 8 with value: 0.7782347282347283.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:22:26,175]\u001b[0m Trial 17 finished with value: 0.774939874939875 and parameters: {'learning_rate': 0.07581793501252262, 'num_leaves': 141, 'max_depth': 9}. Best is trial 8 with value: 0.7782347282347283.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:22:32,012]\u001b[0m Trial 18 finished with value: 0.7694324194324195 and parameters: {'learning_rate': 0.022783765630038286, 'num_leaves': 78, 'max_depth': 11}. Best is trial 8 with value: 0.7782347282347283.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:22:35,575]\u001b[0m Trial 19 finished with value: 0.7636123136123136 and parameters: {'learning_rate': 0.055860985283862186, 'num_leaves': 252, 'max_depth': 6}. Best is trial 8 with value: 0.7782347282347283.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:22:42,751]\u001b[0m Trial 20 finished with value: 0.7754208754208755 and parameters: {'learning_rate': 0.043170282478466215, 'num_leaves': 124, 'max_depth': 9}. Best is trial 8 with value: 0.7782347282347283.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:22:50,957]\u001b[0m Trial 21 finished with value: 0.777970177970178 and parameters: {'learning_rate': 0.044566905447352055, 'num_leaves': 195, 'max_depth': 11}. Best is trial 8 with value: 0.7782347282347283.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:22:59,443]\u001b[0m Trial 22 finished with value: 0.7785714285714286 and parameters: {'learning_rate': 0.05409882229497762, 'num_leaves': 188, 'max_depth': 11}. Best is trial 22 with value: 0.7785714285714286.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:23:09,897]\u001b[0m Trial 23 finished with value: 0.7797739297739298 and parameters: {'learning_rate': 0.052088387345018056, 'num_leaves': 229, 'max_depth': 12}. Best is trial 23 with value: 0.7797739297739298.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:23:18,890]\u001b[0m Trial 24 finished with value: 0.7794853294853296 and parameters: {'learning_rate': 0.05198361636507699, 'num_leaves': 218, 'max_depth': 12}. Best is trial 23 with value: 0.7797739297739298.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:23:28,033]\u001b[0m Trial 25 finished with value: 0.7783549783549782 and parameters: {'learning_rate': 0.05434246447759638, 'num_leaves': 227, 'max_depth': 12}. Best is trial 23 with value: 0.7797739297739298.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:23:36,664]\u001b[0m Trial 26 finished with value: 0.777008177008177 and parameters: {'learning_rate': 0.0688374985624141, 'num_leaves': 224, 'max_depth': 10}. Best is trial 23 with value: 0.7797739297739298.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:23:47,280]\u001b[0m Trial 27 finished with value: 0.78008658008658 and parameters: {'learning_rate': 0.05311974864406935, 'num_leaves': 240, 'max_depth': 12}. Best is trial 27 with value: 0.78008658008658.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:23:56,086]\u001b[0m Trial 28 finished with value: 0.7806878306878305 and parameters: {'learning_rate': 0.07355128877656744, 'num_leaves': 239, 'max_depth': 12}. Best is trial 28 with value: 0.7806878306878305.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:24:07,649]\u001b[0m Trial 29 finished with value: 0.7784271284271284 and parameters: {'learning_rate': 0.07288627411660879, 'num_leaves': 236, 'max_depth': 10}. Best is trial 28 with value: 0.7806878306878305.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:24:10,845]\u001b[0m Trial 30 finished with value: 0.76007696007696 and parameters: {'learning_rate': 0.08149638367531264, 'num_leaves': 239, 'max_depth': 5}. Best is trial 28 with value: 0.7806878306878305.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:24:20,175]\u001b[0m Trial 31 finished with value: 0.7812169312169313 and parameters: {'learning_rate': 0.05913549433662376, 'num_leaves': 253, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:24:28,817]\u001b[0m Trial 32 finished with value: 0.7808561808561808 and parameters: {'learning_rate': 0.06227330755384636, 'num_leaves': 256, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:24:37,451]\u001b[0m Trial 33 finished with value: 0.7804713804713805 and parameters: {'learning_rate': 0.06404327044266181, 'num_leaves': 254, 'max_depth': 11}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:24:46,213]\u001b[0m Trial 34 finished with value: 0.7779220779220779 and parameters: {'learning_rate': 0.06342661564882136, 'num_leaves': 256, 'max_depth': 11}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:24:53,943]\u001b[0m Trial 35 finished with value: 0.7798460798460799 and parameters: {'learning_rate': 0.06927125674954797, 'num_leaves': 207, 'max_depth': 11}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:25:02,985]\u001b[0m Trial 36 finished with value: 0.777032227032227 and parameters: {'learning_rate': 0.06040469720561808, 'num_leaves': 244, 'max_depth': 10}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:25:13,502]\u001b[0m Trial 37 finished with value: 0.7793410293410293 and parameters: {'learning_rate': 0.0659736103012246, 'num_leaves': 173, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:25:20,186]\u001b[0m Trial 38 finished with value: 0.7708994708994709 and parameters: {'learning_rate': 0.07396933581997386, 'num_leaves': 255, 'max_depth': 8}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:25:27,577]\u001b[0m Trial 39 finished with value: 0.7810966810966811 and parameters: {'learning_rate': 0.08228294512966236, 'num_leaves': 205, 'max_depth': 11}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:25:35,259]\u001b[0m Trial 40 finished with value: 0.7804232804232805 and parameters: {'learning_rate': 0.08231872178822436, 'num_leaves': 207, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:25:43,769]\u001b[0m Trial 41 finished with value: 0.7791486291486293 and parameters: {'learning_rate': 0.060055388128587975, 'num_leaves': 232, 'max_depth': 11}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:25:51,169]\u001b[0m Trial 42 finished with value: 0.7797498797498797 and parameters: {'learning_rate': 0.07941629183032775, 'num_leaves': 217, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:25:58,434]\u001b[0m Trial 43 finished with value: 0.7798220298220299 and parameters: {'learning_rate': 0.0882208494933161, 'num_leaves': 239, 'max_depth': 11}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:26:04,843]\u001b[0m Trial 44 finished with value: 0.7761664261664261 and parameters: {'learning_rate': 0.0673918415564037, 'num_leaves': 157, 'max_depth': 10}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:26:13,416]\u001b[0m Trial 45 finished with value: 0.7807118807118808 and parameters: {'learning_rate': 0.06929788711848782, 'num_leaves': 245, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:26:20,922]\u001b[0m Trial 46 finished with value: 0.7804232804232805 and parameters: {'learning_rate': 0.0862785900427096, 'num_leaves': 212, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:26:34,251]\u001b[0m Trial 47 finished with value: 0.7807840307840307 and parameters: {'learning_rate': 0.07114655426605924, 'num_leaves': 244, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:26:43,934]\u001b[0m Trial 48 finished with value: 0.7781866281866282 and parameters: {'learning_rate': 0.06981086738493959, 'num_leaves': 176, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:26:52,498]\u001b[0m Trial 49 finished with value: 0.777994227994228 and parameters: {'learning_rate': 0.07747424251237145, 'num_leaves': 198, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:27:04,266]\u001b[0m Trial 50 finished with value: 0.7784511784511784 and parameters: {'learning_rate': 0.05776163029762432, 'num_leaves': 224, 'max_depth': 11}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:27:15,378]\u001b[0m Trial 51 finished with value: 0.7806397306397307 and parameters: {'learning_rate': 0.07241437850168181, 'num_leaves': 244, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:27:23,962]\u001b[0m Trial 52 finished with value: 0.78008658008658 and parameters: {'learning_rate': 0.06365769146371451, 'num_leaves': 247, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:27:32,607]\u001b[0m Trial 53 finished with value: 0.7785954785954786 and parameters: {'learning_rate': 0.07755929892631683, 'num_leaves': 231, 'max_depth': 11}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:27:40,982]\u001b[0m Trial 54 finished with value: 0.7804954304954306 and parameters: {'learning_rate': 0.07424691815246705, 'num_leaves': 244, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:27:44,800]\u001b[0m Trial 55 finished with value: 0.7680134680134681 and parameters: {'learning_rate': 0.07030154246636339, 'num_leaves': 218, 'max_depth': 7}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:27:48,927]\u001b[0m Trial 56 finished with value: 0.7713564213564214 and parameters: {'learning_rate': 0.0663372005643745, 'num_leaves': 43, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:27:58,737]\u001b[0m Trial 57 finished with value: 0.7762626262626263 and parameters: {'learning_rate': 0.05976613835844882, 'num_leaves': 232, 'max_depth': 11}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:28:05,791]\u001b[0m Trial 58 finished with value: 0.7753246753246753 and parameters: {'learning_rate': 0.049186360168900836, 'num_leaves': 249, 'max_depth': 9}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:28:12,792]\u001b[0m Trial 59 finished with value: 0.7784271284271284 and parameters: {'learning_rate': 0.0986395372311791, 'num_leaves': 186, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:28:21,057]\u001b[0m Trial 60 finished with value: 0.7802068302068301 and parameters: {'learning_rate': 0.05768266618139459, 'num_leaves': 198, 'max_depth': 11}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:28:29,220]\u001b[0m Trial 61 finished with value: 0.7782587782587783 and parameters: {'learning_rate': 0.0741327326015824, 'num_leaves': 244, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:28:39,555]\u001b[0m Trial 62 finished with value: 0.7787878787878788 and parameters: {'learning_rate': 0.07183214953336196, 'num_leaves': 237, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:28:50,454]\u001b[0m Trial 63 finished with value: 0.7792929292929293 and parameters: {'learning_rate': 0.06562231478382856, 'num_leaves': 223, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:28:53,537]\u001b[0m Trial 64 finished with value: 0.7643578643578643 and parameters: {'learning_rate': 0.07099919490570224, 'num_leaves': 255, 'max_depth': 6}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:29:00,717]\u001b[0m Trial 65 finished with value: 0.7787878787878788 and parameters: {'learning_rate': 0.07605294200938216, 'num_leaves': 246, 'max_depth': 11}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:29:08,045]\u001b[0m Trial 66 finished with value: 0.7797017797017798 and parameters: {'learning_rate': 0.06385107451411157, 'num_leaves': 206, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:29:14,763]\u001b[0m Trial 67 finished with value: 0.7796296296296297 and parameters: {'learning_rate': 0.08069082645427149, 'num_leaves': 226, 'max_depth': 12}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:29:22,016]\u001b[0m Trial 68 finished with value: 0.7767436267436268 and parameters: {'learning_rate': 0.0684599203422369, 'num_leaves': 239, 'max_depth': 11}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:29:28,024]\u001b[0m Trial 69 finished with value: 0.7776575276575276 and parameters: {'learning_rate': 0.07245009869156889, 'num_leaves': 153, 'max_depth': 10}. Best is trial 31 with value: 0.7812169312169313.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:29:34,793]\u001b[0m Trial 70 finished with value: 0.7812890812890813 and parameters: {'learning_rate': 0.0769889442438165, 'num_leaves': 215, 'max_depth': 12}. Best is trial 70 with value: 0.7812890812890813.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:29:42,076]\u001b[0m Trial 71 finished with value: 0.7805194805194806 and parameters: {'learning_rate': 0.08341862625242355, 'num_leaves': 249, 'max_depth': 12}. Best is trial 70 with value: 0.7812890812890813.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:29:49,430]\u001b[0m Trial 72 finished with value: 0.7807599807599807 and parameters: {'learning_rate': 0.07881022231465208, 'num_leaves': 234, 'max_depth': 12}. Best is trial 70 with value: 0.7812890812890813.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:29:56,657]\u001b[0m Trial 73 finished with value: 0.7809042809042809 and parameters: {'learning_rate': 0.07666162334430074, 'num_leaves': 213, 'max_depth': 12}. Best is trial 70 with value: 0.7812890812890813.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:30:02,787]\u001b[0m Trial 74 finished with value: 0.7776815776815776 and parameters: {'learning_rate': 0.077502910296596, 'num_leaves': 192, 'max_depth': 12}. Best is trial 70 with value: 0.7812890812890813.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:30:08,661]\u001b[0m Trial 75 finished with value: 0.7773208273208274 and parameters: {'learning_rate': 0.0850451435705396, 'num_leaves': 209, 'max_depth': 11}. Best is trial 70 with value: 0.7812890812890813.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:30:16,152]\u001b[0m Trial 76 finished with value: 0.7802549302549302 and parameters: {'learning_rate': 0.08892656904733962, 'num_leaves': 219, 'max_depth': 12}. Best is trial 70 with value: 0.7812890812890813.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:30:22,856]\u001b[0m Trial 77 finished with value: 0.778042328042328 and parameters: {'learning_rate': 0.08063664751935547, 'num_leaves': 231, 'max_depth': 11}. Best is trial 70 with value: 0.7812890812890813.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:30:28,802]\u001b[0m Trial 78 finished with value: 0.7790764790764791 and parameters: {'learning_rate': 0.07868992991909296, 'num_leaves': 203, 'max_depth': 12}. Best is trial 70 with value: 0.7812890812890813.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:30:30,921]\u001b[0m Trial 79 finished with value: 0.7576960076960079 and parameters: {'learning_rate': 0.07522091774058665, 'num_leaves': 216, 'max_depth': 4}. Best is trial 70 with value: 0.7812890812890813.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:30:32,928]\u001b[0m Trial 80 finished with value: 0.7590668590668589 and parameters: {'learning_rate': 0.06831470023312193, 'num_leaves': 11, 'max_depth': 8}. Best is trial 70 with value: 0.7812890812890813.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:30:40,282]\u001b[0m Trial 81 finished with value: 0.7798220298220299 and parameters: {'learning_rate': 0.07570496975251163, 'num_leaves': 235, 'max_depth': 12}. Best is trial 70 with value: 0.7812890812890813.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:30:46,361]\u001b[0m Trial 82 finished with value: 0.7792448292448292 and parameters: {'learning_rate': 0.07939845891780106, 'num_leaves': 226, 'max_depth': 12}. Best is trial 70 with value: 0.7812890812890813.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:30:53,888]\u001b[0m Trial 83 finished with value: 0.7794372294372295 and parameters: {'learning_rate': 0.07089760502920404, 'num_leaves': 251, 'max_depth': 12}. Best is trial 70 with value: 0.7812890812890813.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:31:02,985]\u001b[0m Trial 84 finished with value: 0.7799422799422798 and parameters: {'learning_rate': 0.08288016002316927, 'num_leaves': 239, 'max_depth': 12}. Best is trial 70 with value: 0.7812890812890813.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:31:11,236]\u001b[0m Trial 85 finished with value: 0.7788840788840788 and parameters: {'learning_rate': 0.06257254158501338, 'num_leaves': 214, 'max_depth': 11}. Best is trial 70 with value: 0.7812890812890813.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:31:18,959]\u001b[0m Trial 86 finished with value: 0.7818662818662819 and parameters: {'learning_rate': 0.0658213036793807, 'num_leaves': 222, 'max_depth': 12}. Best is trial 86 with value: 0.7818662818662819.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:31:26,180]\u001b[0m Trial 87 finished with value: 0.7795334295334295 and parameters: {'learning_rate': 0.06643964802276937, 'num_leaves': 182, 'max_depth': 12}. Best is trial 86 with value: 0.7818662818662819.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:31:32,291]\u001b[0m Trial 88 finished with value: 0.77991822991823 and parameters: {'learning_rate': 0.06158400469913476, 'num_leaves': 133, 'max_depth': 11}. Best is trial 86 with value: 0.7818662818662819.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:31:37,570]\u001b[0m Trial 89 finished with value: 0.7793891293891294 and parameters: {'learning_rate': 0.05571509046990225, 'num_leaves': 93, 'max_depth': 12}. Best is trial 86 with value: 0.7818662818662819.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:31:44,797]\u001b[0m Trial 90 finished with value: 0.7788600288600289 and parameters: {'learning_rate': 0.06501061782218524, 'num_leaves': 203, 'max_depth': 11}. Best is trial 86 with value: 0.7818662818662819.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:31:52,884]\u001b[0m Trial 91 finished with value: 0.7815295815295816 and parameters: {'learning_rate': 0.06853057152400768, 'num_leaves': 256, 'max_depth': 12}. Best is trial 86 with value: 0.7818662818662819.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:32:00,792]\u001b[0m Trial 92 finished with value: 0.7797979797979798 and parameters: {'learning_rate': 0.06804292699964457, 'num_leaves': 254, 'max_depth': 12}. Best is trial 86 with value: 0.7818662818662819.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:32:07,554]\u001b[0m Trial 93 finished with value: 0.7809042809042809 and parameters: {'learning_rate': 0.07018313633047664, 'num_leaves': 221, 'max_depth': 12}. Best is trial 86 with value: 0.7818662818662819.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:32:15,275]\u001b[0m Trial 94 finished with value: 0.7815055315055316 and parameters: {'learning_rate': 0.07632123438823268, 'num_leaves': 223, 'max_depth': 12}. Best is trial 86 with value: 0.7818662818662819.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:32:21,250]\u001b[0m Trial 95 finished with value: 0.7774410774410775 and parameters: {'learning_rate': 0.07218313146127774, 'num_leaves': 221, 'max_depth': 11}. Best is trial 86 with value: 0.7818662818662819.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:32:27,909]\u001b[0m Trial 96 finished with value: 0.7806156806156807 and parameters: {'learning_rate': 0.07588944209871747, 'num_leaves': 228, 'max_depth': 12}. Best is trial 86 with value: 0.7818662818662819.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:32:34,621]\u001b[0m Trial 97 finished with value: 0.7795334295334295 and parameters: {'learning_rate': 0.062075244716524675, 'num_leaves': 212, 'max_depth': 12}. Best is trial 86 with value: 0.7818662818662819.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:32:38,565]\u001b[0m Trial 98 finished with value: 0.7732563732563733 and parameters: {'learning_rate': 0.06590755260396582, 'num_leaves': 73, 'max_depth': 12}. Best is trial 86 with value: 0.7818662818662819.\u001b[0m\n",
      "\u001b[32m[I 2023-05-06 18:32:45,293]\u001b[0m Trial 99 finished with value: 0.7792448292448292 and parameters: {'learning_rate': 0.07316892767740756, 'num_leaves': 256, 'max_depth': 11}. Best is trial 86 with value: 0.7818662818662819.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def objective(trial):\n",
    "\n",
    "    global X_train, X_test, y_train, y_test\n",
    "\n",
    "    def f2_score(y_true, y_pred):\n",
    "        return fbeta_score(y_true, y_pred, beta=2, average='weighted')\n",
    "    f2_scorer = make_scorer(f2_score)\n",
    "\n",
    "\n",
    "    # Define the hyperparameters to optimize\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.001, 0.1),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 12)\n",
    "    }\n",
    "\n",
    "    num_cols = [col for i, col in enumerate(X_train.columns) if X_train[col].dtypes in ['float64', 'int64']]\n",
    "    cat_cols = [col for i, col in enumerate(X_train.columns) if X_train[col].dtypes =='object']\n",
    "    cat_indices = [i for i, col in enumerate(X_train.columns) if X_train[col].dtypes =='object']\n",
    "    cols_with_missing = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "\n",
    "    X_cat = X_train.copy(deep=True)\n",
    "    X_test_cat = X_test.copy(deep=True)\n",
    "\n",
    "    for col in cat_cols:\n",
    "        X_cat[col] = X_cat[col].astype('category')\n",
    "        X_test_cat[col] = X_test_cat[col].astype('category')\n",
    "\n",
    "    y_train_df = pd.Series(y_train)\n",
    "\n",
    "    # set up the wrapper with the SimpleImputer\n",
    "    imputer = SklearnTransformerWrapper(transformer = SimpleImputer(strategy='most_frequent'),\n",
    "                                        variables = cols_with_missing)\n",
    "    # specify columns for standard scaler\n",
    "    scaler = SklearnTransformerWrapper(transformer=StandardScaler(),\n",
    "                                    variables=num_cols)\n",
    "\n",
    "\n",
    "    lgb_model = lgb.LGBMClassifier(**params, \n",
    "                            metric='multi_logloss',\n",
    "                            categorical_feature=cat_indices)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=3, random_state=43, shuffle=True)\n",
    "    f2_scores = []\n",
    "\n",
    "    \n",
    "\n",
    "    for idx, (train_idx, test_idx) in enumerate(skf.split(X_cat, y_train_df)):\n",
    "        X_train_split, X_test_split = X_cat.iloc[train_idx], X_cat.iloc[test_idx]\n",
    "        y_train_split, y_test_split = y_train_df.iloc[train_idx], y_train_df.iloc[test_idx]\n",
    "        \n",
    "        pipeline = Pipeline(steps=[('scaler', scaler),\n",
    "                                   ('lgb_model', lgb_model)])\n",
    "        #model = lgb.LGBMClassifier(**params, categorical_feature=cat_indices)\n",
    "        pipeline.fit(X_train_split, \n",
    "                     y_train_split, \n",
    "                     lgb_model__early_stopping_rounds=50,\n",
    "                     lgb_model__eval_set=[(X_test_split, y_test_split)], \n",
    "                     lgb_model__verbose=False)\n",
    "        \n",
    "        y_pred = pipeline.predict(X_test_split)\n",
    "        f2_score_lgbm = fbeta_score(y_test_split, y_pred, beta=2, average='micro')\n",
    "        f2_scores.append(f2_score_lgbm)\n",
    "        \n",
    "    return np.mean(f2_scores)\n",
    "    \n",
    "\n",
    "study_lgbm = optuna.create_study(direction='maximize')\n",
    "study_lgbm.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc60365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                 SklearnTransformerWrapper(transformer=StandardScaler(),\n",
       "                                           variables=[&#x27;amount_tsh&#x27;,\n",
       "                                                      &#x27;gps_height&#x27;,\n",
       "                                                      &#x27;population&#x27;, &#x27;age&#x27;])),\n",
       "                (&#x27;lgb_model&#x27;,\n",
       "                 LGBMClassifier(categorical_feature=[1, 3, 4, 5, 7, 8, 9, 10,\n",
       "                                                     11, 12, 13, 14, 15, 16],\n",
       "                                learning_rate=0.0658213036793807, max_depth=12,\n",
       "                                metric=&#x27;multi_logloss&#x27;, num_leaves=222))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                 SklearnTransformerWrapper(transformer=StandardScaler(),\n",
       "                                           variables=[&#x27;amount_tsh&#x27;,\n",
       "                                                      &#x27;gps_height&#x27;,\n",
       "                                                      &#x27;population&#x27;, &#x27;age&#x27;])),\n",
       "                (&#x27;lgb_model&#x27;,\n",
       "                 LGBMClassifier(categorical_feature=[1, 3, 4, 5, 7, 8, 9, 10,\n",
       "                                                     11, 12, 13, 14, 15, 16],\n",
       "                                learning_rate=0.0658213036793807, max_depth=12,\n",
       "                                metric=&#x27;multi_logloss&#x27;, num_leaves=222))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">scaler: SklearnTransformerWrapper</label><div class=\"sk-toggleable__content\"><pre>SklearnTransformerWrapper(transformer=StandardScaler(),\n",
       "                          variables=[&#x27;amount_tsh&#x27;, &#x27;gps_height&#x27;, &#x27;population&#x27;,\n",
       "                                     &#x27;age&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformer: StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(categorical_feature=[1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15,\n",
       "                                    16],\n",
       "               learning_rate=0.0658213036793807, max_depth=12,\n",
       "               metric=&#x27;multi_logloss&#x27;, num_leaves=222)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler',\n",
       "                 SklearnTransformerWrapper(transformer=StandardScaler(),\n",
       "                                           variables=['amount_tsh',\n",
       "                                                      'gps_height',\n",
       "                                                      'population', 'age'])),\n",
       "                ('lgb_model',\n",
       "                 LGBMClassifier(categorical_feature=[1, 3, 4, 5, 7, 8, 9, 10,\n",
       "                                                     11, 12, 13, 14, 15, 16],\n",
       "                                learning_rate=0.0658213036793807, max_depth=12,\n",
       "                                metric='multi_logloss', num_leaves=222))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_lgbm = study_lgbm.best_params\n",
    "\n",
    "\n",
    "num_cols = [col for i, col in enumerate(X_train.columns) if X_train[col].dtypes in ['float64', 'int64']]\n",
    "cat_cols = [col for i, col in enumerate(X_train.columns) if X_train[col].dtypes =='object']\n",
    "cat_indices = [i for i, col in enumerate(X_train.columns) if X_train[col].dtypes =='object']\n",
    "cols_with_missing = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "\n",
    "X_cat = X_train.copy(deep=True)\n",
    "X_test_cat = X_test.copy(deep=True)\n",
    "\n",
    "for col in cat_cols:\n",
    "    X_cat[col] = X_cat[col].astype('category')\n",
    "    X_test_cat[col] = X_test_cat[col].astype('category')\n",
    "\n",
    "y_train_df = pd.Series(y_train)\n",
    "\n",
    "# set up the wrapper with the SimpleImputer\n",
    "imputer = SklearnTransformerWrapper(transformer = SimpleImputer(strategy='most_frequent'),\n",
    "                                    variables = cols_with_missing)\n",
    "# specify columns for standard scaler\n",
    "scaler = SklearnTransformerWrapper(transformer=StandardScaler(),\n",
    "                                variables=num_cols)\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(**best_params_lgbm, \n",
    "                        metric='multi_logloss',\n",
    "                        categorical_feature=cat_indices)\n",
    "\n",
    "\n",
    "pipeline_lgbm = Pipeline(steps=[('scaler', SklearnTransformerWrapper(transformer = SimpleImputer(strategy='most_frequent'),\n",
    "                                    variables = cols_with_missing)),\n",
    "                            ('lgb_model', SklearnTransformerWrapper(transformer=StandardScaler(),\n",
    "                                variables=num_cols))])\n",
    "#model = lgb.LGBMClassifier(**params, categorical_feature=cat_indices)\n",
    "pipeline_lgbm.fit(X_cat, \n",
    "                y_train, \n",
    "                lgb_model__early_stopping_rounds=50,\n",
    "                lgb_model__eval_set=[(X_test_cat, y_test)], \n",
    "                lgb_model__verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c908153e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7884399551066218"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lgbm = pipeline_lgbm.predict(X_test_cat)\n",
    "f2_score_lgbm = fbeta_score(y_test, y_pred_lgbm, beta=2, average='micro')\n",
    "f2_score_lgbm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d55d2ec",
   "metadata": {},
   "source": [
    "### XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fe48aa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-07 04:52:15,106]\u001b[0m A new study created in memory with name: no-name-da762ada-1a6b-4bf5-98e8-5810e0284277\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 04:53:31,621]\u001b[0m Trial 0 finished with value: 0.7600769600769602 and parameters: {'n_estimators': 950, 'max_depth': 4, 'gamma': 0.15328973099944287, 'subsample': 0.9806749144655965, 'colsample_bytree': 0.9969961248095411, 'learning_rate': 0.03220791041045677}. Best is trial 0 with value: 0.7600769600769602.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 04:53:45,848]\u001b[0m Trial 1 finished with value: 0.7787878787878788 and parameters: {'n_estimators': 500, 'max_depth': 9, 'gamma': 0.7219079231432345, 'subsample': 0.93853801727357, 'colsample_bytree': 0.9180211700304204, 'learning_rate': 0.7600468259519796}. Best is trial 1 with value: 0.7787878787878788.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 04:54:04,054]\u001b[0m Trial 2 finished with value: 0.7740981240981241 and parameters: {'n_estimators': 700, 'max_depth': 4, 'gamma': 0.8555956940007117, 'subsample': 0.5413635706692382, 'colsample_bytree': 0.6231138500223221, 'learning_rate': 0.542236085500738}. Best is trial 1 with value: 0.7787878787878788.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 04:54:36,167]\u001b[0m Trial 3 finished with value: 0.7751563251563253 and parameters: {'n_estimators': 900, 'max_depth': 4, 'gamma': 0.6347577229957683, 'subsample': 0.9630699030122336, 'colsample_bytree': 0.9565016981247647, 'learning_rate': 0.6471652580197581}. Best is trial 1 with value: 0.7787878787878788.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 04:54:51,272]\u001b[0m Trial 4 finished with value: 0.778090428090428 and parameters: {'n_estimators': 400, 'max_depth': 8, 'gamma': 0.3333129369263941, 'subsample': 0.8477259237385586, 'colsample_bytree': 0.8888617380792357, 'learning_rate': 0.6696268025266638}. Best is trial 1 with value: 0.7787878787878788.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 04:55:04,395]\u001b[0m Trial 5 finished with value: 0.7760461760461762 and parameters: {'n_estimators': 300, 'max_depth': 10, 'gamma': 0.16448814955339208, 'subsample': 0.6675443254451798, 'colsample_bytree': 0.7864274677337295, 'learning_rate': 0.7032728648847514}. Best is trial 1 with value: 0.7787878787878788.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 04:55:41,421]\u001b[0m Trial 6 finished with value: 0.7742183742183743 and parameters: {'n_estimators': 650, 'max_depth': 3, 'gamma': 0.9174911617582543, 'subsample': 0.6102524422214569, 'colsample_bytree': 0.8291219154968767, 'learning_rate': 0.39652155836568775}. Best is trial 1 with value: 0.7787878787878788.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 04:55:54,950]\u001b[0m Trial 7 finished with value: 0.7815055315055316 and parameters: {'n_estimators': 100, 'max_depth': 10, 'gamma': 0.2554294259334623, 'subsample': 0.50600864683389, 'colsample_bytree': 0.5886275654127184, 'learning_rate': 0.4482509441985143}. Best is trial 7 with value: 0.7815055315055316.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 04:56:06,793]\u001b[0m Trial 8 finished with value: 0.7777777777777777 and parameters: {'n_estimators': 950, 'max_depth': 10, 'gamma': 0.15314893392510043, 'subsample': 0.8186262988463142, 'colsample_bytree': 0.7578740214409057, 'learning_rate': 0.7651448955245391}. Best is trial 7 with value: 0.7815055315055316.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 04:56:18,652]\u001b[0m Trial 9 finished with value: 0.7717652717652718 and parameters: {'n_estimators': 550, 'max_depth': 6, 'gamma': 0.9279954910470372, 'subsample': 0.6167442848898833, 'colsample_bytree': 0.768339734733571, 'learning_rate': 0.8628999684139445}. Best is trial 7 with value: 0.7815055315055316.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 04:56:23,711]\u001b[0m Trial 10 finished with value: 0.7684463684463685 and parameters: {'n_estimators': 50, 'max_depth': 7, 'gamma': 0.42323006139474684, 'subsample': 0.5016441181178797, 'colsample_bytree': 0.5105435207342581, 'learning_rate': 0.9676713455338768}. Best is trial 7 with value: 0.7815055315055316.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 04:56:42,586]\u001b[0m Trial 11 finished with value: 0.7832852332852333 and parameters: {'n_estimators': 150, 'max_depth': 9, 'gamma': 0.6345171732668453, 'subsample': 0.746032463837288, 'colsample_bytree': 0.6618457428970657, 'learning_rate': 0.39500759702730437}. Best is trial 11 with value: 0.7832852332852333.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 04:56:49,197]\u001b[0m Trial 12 finished with value: 0.7777537277537278 and parameters: {'n_estimators': 50, 'max_depth': 8, 'gamma': 0.5073421500374532, 'subsample': 0.7272319456609982, 'colsample_bytree': 0.6487061804549765, 'learning_rate': 0.33710356185681745}. Best is trial 11 with value: 0.7832852332852333.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 04:57:10,156]\u001b[0m Trial 13 finished with value: 0.7837902837902838 and parameters: {'n_estimators': 200, 'max_depth': 9, 'gamma': 0.3090351089941804, 'subsample': 0.7345016614284695, 'colsample_bytree': 0.6668511711243542, 'learning_rate': 0.32463871451573356}. Best is trial 13 with value: 0.7837902837902838.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 04:57:36,162]\u001b[0m Trial 14 finished with value: 0.78006253006253 and parameters: {'n_estimators': 250, 'max_depth': 6, 'gamma': 0.5280913906460709, 'subsample': 0.7544166901168085, 'colsample_bytree': 0.691133017194645, 'learning_rate': 0.26017315603395874}. Best is trial 13 with value: 0.7837902837902838.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 04:58:00,744]\u001b[0m Trial 15 finished with value: 0.785016835016835 and parameters: {'n_estimators': 200, 'max_depth': 8, 'gamma': 0.36578212566073876, 'subsample': 0.7371769966368701, 'colsample_bytree': 0.7048087550393493, 'learning_rate': 0.22406625884360373}. Best is trial 15 with value: 0.785016835016835.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 04:58:26,511]\u001b[0m Trial 16 finished with value: 0.7822029822029822 and parameters: {'n_estimators': 250, 'max_depth': 7, 'gamma': 0.004107424405161986, 'subsample': 0.8168118192917873, 'colsample_bytree': 0.7092278636472125, 'learning_rate': 0.2389788309422204}. Best is trial 15 with value: 0.785016835016835.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 04:59:12,322]\u001b[0m Trial 17 finished with value: 0.7864117364117366 and parameters: {'n_estimators': 400, 'max_depth': 8, 'gamma': 0.3831740019587054, 'subsample': 0.6846570768752248, 'colsample_bytree': 0.713895487623545, 'learning_rate': 0.13800116277809482}. Best is trial 17 with value: 0.7864117364117366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:00:03,015]\u001b[0m Trial 18 finished with value: 0.7855459355459354 and parameters: {'n_estimators': 400, 'max_depth': 8, 'gamma': 0.4385366817979877, 'subsample': 0.6765294831486739, 'colsample_bytree': 0.7054185675541017, 'learning_rate': 0.11401648774829452}. Best is trial 17 with value: 0.7864117364117366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:00:53,423]\u001b[0m Trial 19 finished with value: 0.7612794612794612 and parameters: {'n_estimators': 450, 'max_depth': 6, 'gamma': 0.48905766417524676, 'subsample': 0.671161367144293, 'colsample_bytree': 0.8221988509800291, 'learning_rate': 0.01956685909636613}. Best is trial 17 with value: 0.7864117364117366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:01:48,289]\u001b[0m Trial 20 finished with value: 0.783934583934584 and parameters: {'n_estimators': 750, 'max_depth': 7, 'gamma': 0.43871117610085647, 'subsample': 0.5836268817696522, 'colsample_bytree': 0.7261452891901492, 'learning_rate': 0.1241328245330392}. Best is trial 17 with value: 0.7864117364117366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:02:23,001]\u001b[0m Trial 21 finished with value: 0.7853535353535354 and parameters: {'n_estimators': 350, 'max_depth': 8, 'gamma': 0.3783073701920499, 'subsample': 0.6746457753673449, 'colsample_bytree': 0.7257236274145105, 'learning_rate': 0.17680413406559076}. Best is trial 17 with value: 0.7864117364117366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:03:08,101]\u001b[0m Trial 22 finished with value: 0.7859307359307359 and parameters: {'n_estimators': 350, 'max_depth': 8, 'gamma': 0.3959802949690357, 'subsample': 0.667463477259841, 'colsample_bytree': 0.7448146400999974, 'learning_rate': 0.1335997525477947}. Best is trial 17 with value: 0.7864117364117366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:03:57,728]\u001b[0m Trial 23 finished with value: 0.785882635882636 and parameters: {'n_estimators': 550, 'max_depth': 9, 'gamma': 0.27343717834946635, 'subsample': 0.6405609911840395, 'colsample_bytree': 0.7949585263202537, 'learning_rate': 0.11413026325331417}. Best is trial 17 with value: 0.7864117364117366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:04:56,568]\u001b[0m Trial 24 finished with value: 0.7865560365560365 and parameters: {'n_estimators': 550, 'max_depth': 9, 'gamma': 0.21171672363934313, 'subsample': 0.6240251466609965, 'colsample_bytree': 0.8052359622057116, 'learning_rate': 0.09301252660878445}. Best is trial 24 with value: 0.7865560365560365.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:06:36,176]\u001b[0m Trial 25 finished with value: 0.7801106301106301 and parameters: {'n_estimators': 600, 'max_depth': 9, 'gamma': 0.23478179403532493, 'subsample': 0.5799094592001923, 'colsample_bytree': 0.8447610967637429, 'learning_rate': 0.02048907846390545}. Best is trial 24 with value: 0.7865560365560365.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:07:16,678]\u001b[0m Trial 26 finished with value: 0.781986531986532 and parameters: {'n_estimators': 800, 'max_depth': 7, 'gamma': 0.3651758814664985, 'subsample': 0.5659363246952289, 'colsample_bytree': 0.7528404785890652, 'learning_rate': 0.17332776593618476}. Best is trial 24 with value: 0.7865560365560365.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:07:42,044]\u001b[0m Trial 27 finished with value: 0.782948532948533 and parameters: {'n_estimators': 450, 'max_depth': 10, 'gamma': 0.04795628890833584, 'subsample': 0.6342613816794833, 'colsample_bytree': 0.8059557727270132, 'learning_rate': 0.29033364318534205}. Best is trial 24 with value: 0.7865560365560365.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:08:16,365]\u001b[0m Trial 28 finished with value: 0.7714766714766714 and parameters: {'n_estimators': 350, 'max_depth': 5, 'gamma': 0.28667356050674475, 'subsample': 0.7112317332574414, 'colsample_bytree': 0.875458832521917, 'learning_rate': 0.0834821820591595}. Best is trial 24 with value: 0.7865560365560365.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:09:27,965]\u001b[0m Trial 29 finished with value: 0.7859307359307359 and parameters: {'n_estimators': 500, 'max_depth': 8, 'gamma': 0.20185134961172038, 'subsample': 0.6096280051161391, 'colsample_bytree': 0.7765875903160454, 'learning_rate': 0.07428039591261208}. Best is trial 24 with value: 0.7865560365560365.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:10:03,679]\u001b[0m Trial 30 finished with value: 0.7856902356902357 and parameters: {'n_estimators': 600, 'max_depth': 9, 'gamma': 0.11892303532924298, 'subsample': 0.7002993752692633, 'colsample_bytree': 0.7422561739861466, 'learning_rate': 0.17391348806152435}. Best is trial 24 with value: 0.7865560365560365.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:11:12,896]\u001b[0m Trial 31 finished with value: 0.7862193362193363 and parameters: {'n_estimators': 500, 'max_depth': 8, 'gamma': 0.21786158020170274, 'subsample': 0.6110365100830002, 'colsample_bytree': 0.7799959523764476, 'learning_rate': 0.07407144553182236}. Best is trial 24 with value: 0.7865560365560365.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:12:14,798]\u001b[0m Trial 32 finished with value: 0.7752765752765752 and parameters: {'n_estimators': 450, 'max_depth': 8, 'gamma': 0.20783725903670036, 'subsample': 0.6480184945950496, 'colsample_bytree': 0.7981564462900437, 'learning_rate': 0.02253436301824987}. Best is trial 24 with value: 0.7865560365560365.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:13:10,873]\u001b[0m Trial 33 finished with value: 0.785064935064935 and parameters: {'n_estimators': 350, 'max_depth': 9, 'gamma': 0.31036994932359513, 'subsample': 0.5545891748142524, 'colsample_bytree': 0.8543649216297884, 'learning_rate': 0.0788986453196932}. Best is trial 24 with value: 0.7865560365560365.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:13:49,020]\u001b[0m Trial 34 finished with value: 0.7846560846560847 and parameters: {'n_estimators': 650, 'max_depth': 7, 'gamma': 0.1074172801917761, 'subsample': 0.5970106509791551, 'colsample_bytree': 0.7535530840466237, 'learning_rate': 0.19164301685011237}. Best is trial 24 with value: 0.7865560365560365.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:14:36,785]\u001b[0m Trial 35 finished with value: 0.7867484367484368 and parameters: {'n_estimators': 500, 'max_depth': 9, 'gamma': 0.21731902962059219, 'subsample': 0.6377122051282024, 'colsample_bytree': 0.9108618990070679, 'learning_rate': 0.14299777831819485}. Best is trial 35 with value: 0.7867484367484368.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:16:03,561]\u001b[0m Trial 36 finished with value: 0.7874699374699374 and parameters: {'n_estimators': 500, 'max_depth': 9, 'gamma': 0.2145844562664468, 'subsample': 0.6284136305175798, 'colsample_bytree': 0.9318169973978295, 'learning_rate': 0.05487582875095254}. Best is trial 36 with value: 0.7874699374699374.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:16:30,603]\u001b[0m Trial 37 finished with value: 0.784078884078884 and parameters: {'n_estimators': 700, 'max_depth': 10, 'gamma': 0.1732517145477115, 'subsample': 0.5472264428382184, 'colsample_bytree': 0.9420293865437974, 'learning_rate': 0.2392872273698896}. Best is trial 36 with value: 0.7874699374699374.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:17:14,874]\u001b[0m Trial 38 finished with value: 0.7850889850889851 and parameters: {'n_estimators': 600, 'max_depth': 9, 'gamma': 0.2888441455780267, 'subsample': 0.6343257614333541, 'colsample_bytree': 0.9981842825528624, 'learning_rate': 0.1546247032125848}. Best is trial 36 with value: 0.7874699374699374.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:20:06,670]\u001b[0m Trial 39 finished with value: 0.782996632996633 and parameters: {'n_estimators': 850, 'max_depth': 10, 'gamma': 0.1041646094978852, 'subsample': 0.5753520956771926, 'colsample_bytree': 0.9166193335014152, 'learning_rate': 0.013318189958451118}. Best is trial 36 with value: 0.7874699374699374.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:20:22,008]\u001b[0m Trial 40 finished with value: 0.7763828763828764 and parameters: {'n_estimators': 400, 'max_depth': 10, 'gamma': 0.24274351450010273, 'subsample': 0.5338485239894695, 'colsample_bytree': 0.9698642858676837, 'learning_rate': 0.5538945106917812}. Best is trial 36 with value: 0.7874699374699374.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:21:43,599]\u001b[0m Trial 41 finished with value: 0.7867724867724868 and parameters: {'n_estimators': 500, 'max_depth': 9, 'gamma': 0.2128738717276944, 'subsample': 0.6094735526433299, 'colsample_bytree': 0.9016417580918732, 'learning_rate': 0.07079007000324511}. Best is trial 36 with value: 0.7874699374699374.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:23:07,074]\u001b[0m Trial 42 finished with value: 0.7866281866281867 and parameters: {'n_estimators': 500, 'max_depth': 9, 'gamma': 0.1682365397930881, 'subsample': 0.6242924576693875, 'colsample_bytree': 0.8978706219561423, 'learning_rate': 0.0665785044566754}. Best is trial 36 with value: 0.7874699374699374.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:24:45,657]\u001b[0m Trial 43 finished with value: 0.7857623857623858 and parameters: {'n_estimators': 550, 'max_depth': 9, 'gamma': 0.15528051224412073, 'subsample': 0.5925449911998907, 'colsample_bytree': 0.9005923490147292, 'learning_rate': 0.040489454505633404}. Best is trial 36 with value: 0.7874699374699374.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:25:18,767]\u001b[0m Trial 44 finished with value: 0.7612554112554113 and parameters: {'n_estimators': 500, 'max_depth': 3, 'gamma': 0.07367843858274306, 'subsample': 0.61728148226125, 'colsample_bytree': 0.9340145509370134, 'learning_rate': 0.09081780888274196}. Best is trial 36 with value: 0.7874699374699374.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:27:00,457]\u001b[0m Trial 45 finished with value: 0.7879509379509381 and parameters: {'n_estimators': 650, 'max_depth': 9, 'gamma': 0.17380305567647278, 'subsample': 0.6493511692252932, 'colsample_bytree': 0.8873409678658584, 'learning_rate': 0.05665644063175673}. Best is trial 45 with value: 0.7879509379509381.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:28:44,140]\u001b[0m Trial 46 finished with value: 0.7880952380952381 and parameters: {'n_estimators': 650, 'max_depth': 10, 'gamma': 0.1608750938788017, 'subsample': 0.6470268147984296, 'colsample_bytree': 0.9677662627212146, 'learning_rate': 0.05265371936718535}. Best is trial 46 with value: 0.7880952380952381.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:29:17,136]\u001b[0m Trial 47 finished with value: 0.7857864357864358 and parameters: {'n_estimators': 700, 'max_depth': 10, 'gamma': 0.12437503098858038, 'subsample': 0.6510157161924469, 'colsample_bytree': 0.9685815509688998, 'learning_rate': 0.1995956563475311}. Best is trial 46 with value: 0.7880952380952381.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:30:55,079]\u001b[0m Trial 48 finished with value: 0.7872534872534872 and parameters: {'n_estimators': 1000, 'max_depth': 10, 'gamma': 0.3355049166713744, 'subsample': 0.5293125148971671, 'colsample_bytree': 0.9725565385632899, 'learning_rate': 0.05041334679247644}. Best is trial 46 with value: 0.7880952380952381.\u001b[0m\n",
      "\u001b[32m[I 2023-05-07 05:32:54,054]\u001b[0m Trial 49 finished with value: 0.788071188071188 and parameters: {'n_estimators': 850, 'max_depth': 10, 'gamma': 0.3226477541492399, 'subsample': 0.5270950103534362, 'colsample_bytree': 0.9826801850713682, 'learning_rate': 0.04715395859044254}. Best is trial 46 with value: 0.7880952380952381.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    " # define the objective function for Optuna to minimize\n",
    "def objective(trial):\n",
    "    # define hyperparameters to tune with Optuna\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000, 50),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1)\n",
    "    }\n",
    "    \n",
    "    # Define the column transformer\n",
    "    cat_var = [ind for ind, col in enumerate(X_train.columns) if X_train[col].dtypes=='object']\n",
    "    num_var = [ind for ind, col in enumerate(X_train.columns) if X_train[col].dtypes in ['int64', 'float64']]\n",
    "\n",
    "    # Define column transformer for one-hot encoding categorical features\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Define column transformer for scaling numeric features\n",
    "    numerical_transformer = Pipeline([\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Define preprocessing pipeline\n",
    "    preprocessing_pipeline = ColumnTransformer([\n",
    "        ('cat_transformer', categorical_transformer, cat_var),\n",
    "        ('num_transformer', numerical_transformer, num_var)\n",
    "    # replace missing categorical values with mode and one-hot encode\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "\n",
    "    # create an XGBoost classifier\n",
    "    xgb_model = xgb.XGBClassifier(**params, \n",
    "                                objective='multi:softmax', \n",
    "                                eval_metric='mlogloss',\n",
    "                                seed=42)\n",
    "\n",
    "    # Define final pipeline with preprocessing and logistic regression model\n",
    "    pipeline_xgb= Pipeline([('preprocessing', preprocessing_pipeline)])\n",
    "    y_train_df = pd.Series(y_train)\n",
    "    \n",
    "\n",
    "    skf = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)\n",
    "    f2_scores = []\n",
    "\n",
    "    for idx, (train_idx, test_idx) in enumerate(skf.split(X_train, y_train_df)):\n",
    "        X_train_split, X_test_split = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "        y_train_split, y_test_split = y_train_df.iloc[train_idx], y_train_df.iloc[test_idx]\n",
    "    \n",
    "        X_train_split = pipeline_xgb.fit_transform(X_train_split)\n",
    "        X_test_split = pipeline_xgb.transform(X_test_split)\n",
    "\n",
    "        xgb_model.fit(X_train_split, y_train_split,\n",
    "                      eval_set=[(X_test_split, y_test_split)],\n",
    "                      early_stopping_rounds=50,\n",
    "                      verbose=False)\n",
    "        \n",
    "        y_pred = xgb_model.predict(X_test_split)\n",
    "        f2_score_xgb = fbeta_score(y_test_split, y_pred, beta=2, average='micro')\n",
    "        f2_scores.append(f2_score_xgb)\n",
    "    return np.mean(f2_scores)\n",
    "\n",
    "# create an Optuna study\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4915739",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'study_xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# obtain best hyperparameters\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_params_xgb \u001b[39m=\u001b[39m study_xgb\u001b[39m.\u001b[39mbest_params\n\u001b[0;32m      4\u001b[0m \u001b[39m# identify the categorical and numeric features\u001b[39;00m\n\u001b[0;32m      5\u001b[0m cat_var \u001b[39m=\u001b[39m [ind \u001b[39mfor\u001b[39;00m ind, col \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(X_train\u001b[39m.\u001b[39mcolumns) \u001b[39mif\u001b[39;00m X_train[col]\u001b[39m.\u001b[39mdtypes\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'study_xgb' is not defined"
     ]
    }
   ],
   "source": [
    "# obtain best hyperparameters\n",
    "best_params_xgb = study_xgb.best_params\n",
    "\n",
    "# identify the categorical and numeric features\n",
    "cat_var = [ind for ind, col in enumerate(X_train.columns) if X_train[col].dtypes=='object']\n",
    "num_var = [ind for ind, col in enumerate(X_train.columns) if X_train[col].dtypes in ['int64', 'float64']]\n",
    "\n",
    "# Define column transformer for one-hot encoding categorical features\n",
    "categorical_transformer = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Define column transformer for scaling numeric features\n",
    "numerical_transformer = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    ('cat_transformer', categorical_transformer, cat_var),\n",
    "    ('num_transformer', numerical_transformer, num_var)\n",
    "# replace missing categorical values with mode and one-hot encode\n",
    "], remainder='passthrough')\n",
    "\n",
    "\n",
    "# create an XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(**best_params_xgb, \n",
    "                            objective='multi:softmax', \n",
    "                            eval_metric='mlogloss',\n",
    "                            seed=42)\n",
    "\n",
    "# Define final pipeline with preprocessing and logistic regression model\n",
    "pipeline_xgb= Pipeline([('preprocessing', preprocessing_pipeline),\n",
    "                        ('xgb_model', xgb_model)])\n",
    "\n",
    "X_train_xgb = pipeline_xgb.fit_transform(X_train)\n",
    "X_test_xgb = pipeline_xgb.transform(X_test)\n",
    "\n",
    "pipeline_xgb.fit(X_train, y_train)\n",
    "pipeline_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "26d74bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7989337822671156"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_xgb = xgb_model.predict(X_test_xgb)\n",
    "f2_score_xgb = fbeta_score(y_test, y_pred_xgb, beta=2, average='micro')\n",
    "f2_score_xgb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cad49133",
   "metadata": {},
   "source": [
    "### Save the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ae4f8c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the training and testing data \n",
    "with open('models/X_train.pkl', 'wb') as f:\n",
    "    pickle.dump(X_train, f)\n",
    "with open('models/X_test.pkl', 'wb') as f:\n",
    "    pickle.dump(X_test, f)\n",
    "with open('models/y_train.pkl', 'wb') as f:\n",
    "    pickle.dump(y_train, f)\n",
    "with open('models/y_test.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4f4d11df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the  tested models \n",
    "with open('models/dummy_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(dummy_clf, f)\n",
    "with open('models/logistic_regression.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline_log, f)\n",
    "with open('models/catboost_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline_cbc, f)\n",
    "with open('models/lgbm_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline_lgbm, f)\n",
    "with open('models/xgb_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline_xgb, f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cc3458c",
   "metadata": {},
   "source": [
    "1. lack of understanding of variables (hard to address many unique values)\n",
    "2. Lack of information on business constraints (cost of repairing/replacing a water pump)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b759a6da",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8df44c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
